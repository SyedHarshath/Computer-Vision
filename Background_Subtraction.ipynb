{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SyedHarshath/Computer-Vision/blob/main/Background_Subtraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acdce83a-48fc-47ea-b11c-b17e25f78f87",
      "metadata": {
        "id": "acdce83a-48fc-47ea-b11c-b17e25f78f87"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09dae8ff-37f3-43cf-9420-389e42921889",
      "metadata": {
        "id": "09dae8ff-37f3-43cf-9420-389e42921889"
      },
      "source": [
        "### Background Subtraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d661c61-36fd-4ee2-958a-e1d56577dfa5",
      "metadata": {
        "id": "6d661c61-36fd-4ee2-958a-e1d56577dfa5"
      },
      "outputs": [],
      "source": [
        "def compute_background(video_path, num_frames=30):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frames = []\n",
        "    count = 0\n",
        "    while count < num_frames:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        frames.append(gray.astype(\"float\"))\n",
        "        count += 1\n",
        "    cap.release()\n",
        "    avg_background = np.mean(frames, axis=0).astype(\"uint8\")\n",
        "    return avg_background"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8375615f-b01d-44f8-b66b-38b10f14ded4",
      "metadata": {
        "id": "8375615f-b01d-44f8-b66b-38b10f14ded4",
        "outputId": "d547e835-6d95-4c25-e156-ab8283e04683"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing Indoor Background...\n",
            "Processing Indoor Video...\n",
            "Computing Outdoor Background...\n",
            "Processing Outdoor Video...\n"
          ]
        }
      ],
      "source": [
        "def subtract_background(video_path, background, threshold=30):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        diff = cv2.absdiff(gray, background)\n",
        "        _, fg_mask = cv2.threshold(diff, threshold, 255, cv2.THRESH_BINARY)\n",
        "        frame = cv2.resize(frame,(512,512))\n",
        "        fg_mask = cv2.resize(fg_mask,(512,512))\n",
        "        cv2.imshow('Original', frame)\n",
        "        cv2.imshow('Foreground Mask', fg_mask)\n",
        "        if cv2.waitKey(30) & 0xFF == 27:\n",
        "            break\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "indoor_path = 'indoor.mp4'\n",
        "outdoor_path = 'forest.mp4'\n",
        "print(\"Computing Indoor Background...\")\n",
        "bg_indoor = compute_background(indoor_path)\n",
        "print(\"Processing Indoor Video...\")\n",
        "subtract_background(indoor_path, bg_indoor)\n",
        "print(\"Computing Outdoor Background...\")\n",
        "bg_outdoor = compute_background(outdoor_path)\n",
        "print(\"Processing Outdoor Video...\")\n",
        "subtract_background(outdoor_path, bg_outdoor)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c58f8dd-7f39-4467-86b5-d128d20fc592",
      "metadata": {
        "id": "0c58f8dd-7f39-4467-86b5-d128d20fc592"
      },
      "source": [
        "### Motion Tracking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "994eadd7-7cb7-419e-b373-0b0173865716",
      "metadata": {
        "id": "994eadd7-7cb7-419e-b373-0b0173865716"
      },
      "outputs": [],
      "source": [
        "video_path = \"op.mp4\"\n",
        "save_output = True\n",
        "min_area = 1500\n",
        "min_width, min_height = 30, 30\n",
        "alpha = 0.03\n",
        "frame_size = (512, 512)\n",
        "colors = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "627ec05f-4f8e-40f8-943e-fe7a2dd63514",
      "metadata": {
        "id": "627ec05f-4f8e-40f8-943e-fe7a2dd63514"
      },
      "outputs": [],
      "source": [
        "def get_color(object_id):\n",
        "    if object_id not in colors:\n",
        "        colors[object_id] = (random.randint(100, 255), random.randint(100, 255), random.randint(100, 255))\n",
        "    return colors[object_id]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b38f1ca-e9d7-4011-97df-ea1e608ff6cb",
      "metadata": {
        "id": "9b38f1ca-e9d7-4011-97df-ea1e608ff6cb"
      },
      "outputs": [],
      "source": [
        "cap = cv2.VideoCapture(video_path)\n",
        "ret, frame = cap.read()\n",
        "frame = cv2.resize(frame, frame_size)\n",
        "gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "background = gray.astype(\"float\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cc4fae6-4ca2-47d2-bfc1-b966d629bbbe",
      "metadata": {
        "id": "8cc4fae6-4ca2-47d2-bfc1-b966d629bbbe"
      },
      "outputs": [],
      "source": [
        "if save_output:\n",
        "    out_tracked = cv2.VideoWriter(\"tracked_output.avi\", cv2.VideoWriter_fourcc(*\"XVID\"), 20, frame_size)\n",
        "    out_fgmask = cv2.VideoWriter(\"foreground_output.avi\", cv2.VideoWriter_fourcc(*\"XVID\"), 20, frame_size)\n",
        "\n",
        "object_id = 0\n",
        "centroids_prev = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fe7b5af-0505-43fd-994f-ab96f34acb53",
      "metadata": {
        "id": "0fe7b5af-0505-43fd-994f-ab96f34acb53"
      },
      "outputs": [],
      "source": [
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    frame = cv2.resize(frame, frame_size)\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    cv2.accumulateWeighted(gray, background, alpha)\n",
        "    bg = cv2.convertScaleAbs(background)\n",
        "    diff = cv2.absdiff(gray, bg)\n",
        "    _, fg_mask = cv2.threshold(diff, 40, 255, cv2.THRESH_BINARY)\n",
        "    kernel = np.ones((3, 3), np.uint8)\n",
        "    fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_OPEN, kernel)\n",
        "    fg_mask = cv2.dilate(fg_mask, kernel, iterations=2)\n",
        "    contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    centroids_curr = {}\n",
        "    for cnt in contours:\n",
        "        if cv2.contourArea(cnt) < min_area:\n",
        "            continue\n",
        "        x, y, w, h = cv2.boundingRect(cnt)\n",
        "        if w < min_width or h < min_height:\n",
        "            continue\n",
        "        centroid = (int(x + w / 2), int(y + h / 2))\n",
        "        matched_id = None\n",
        "        for cid, prev_centroid in centroids_prev.items():\n",
        "            if abs(prev_centroid[0] - centroid[0]) < 30 and abs(prev_centroid[1] - centroid[1]) < 30:\n",
        "                matched_id = cid\n",
        "                break\n",
        "        if matched_id is None:\n",
        "            matched_id = object_id\n",
        "            object_id += 1\n",
        "        centroids_curr[matched_id] = centroid\n",
        "        color = get_color(matched_id)\n",
        "        cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
        "        cv2.putText(frame, f\"ID {matched_id}\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
        "        cv2.circle(frame, centroid, 4, color, -1)\n",
        "    centroids_prev = centroids_curr.copy()\n",
        "    fg_mask_color = cv2.cvtColor(fg_mask, cv2.COLOR_GRAY2BGR)\n",
        "    cv2.imshow(\"Tracked Objects\", frame)\n",
        "    cv2.imshow(\"Foreground\", fg_mask)\n",
        "    if save_output:\n",
        "        out_tracked.write(frame)\n",
        "        out_fgmask.write(fg_mask_color)\n",
        "    if cv2.waitKey(30) & 0xFF == 27:\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "if save_output:\n",
        "    out_tracked.release()\n",
        "    out_fgmask.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4efc3896-740f-422e-adef-9c7171d4e495",
      "metadata": {
        "id": "4efc3896-740f-422e-adef-9c7171d4e495"
      },
      "source": [
        "### Scene Change Estimation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2846e6c8-2450-4db3-8444-93067db48219",
      "metadata": {
        "id": "2846e6c8-2450-4db3-8444-93067db48219"
      },
      "outputs": [],
      "source": [
        "def compute_background(video_path, num_frames=30):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frames = []\n",
        "    count = 0\n",
        "    while count < num_frames:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        frames.append(gray.astype(\"float\"))\n",
        "        count += 1\n",
        "    cap.release()\n",
        "    avg_background = np.mean(frames, axis=0).astype(\"uint8\")\n",
        "    return avg_background"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "675a96d1-282d-4ad9-8a4d-6a65cf85a56e",
      "metadata": {
        "id": "675a96d1-282d-4ad9-8a4d-6a65cf85a56e"
      },
      "outputs": [],
      "source": [
        "def estimate_scene_threshold(video_path, threshold_pixel=25, sample_count=10):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    diffs = []\n",
        "    ret, frame1 = cap.read()\n",
        "    if not ret:\n",
        "        cap.release()\n",
        "        return 0.05\n",
        "    prev = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
        "    for _ in range(sample_count):\n",
        "        ret, frame2 = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        gray = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
        "        diff = cv2.absdiff(gray, prev)\n",
        "        ratio = np.sum(diff > threshold_pixel) / diff.size\n",
        "        diffs.append(ratio)\n",
        "        prev = gray\n",
        "    cap.release()\n",
        "    return np.mean(diffs) + 2 * np.std(diffs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a55baaaf-97bc-4ac7-abf9-48d4a93db371",
      "metadata": {
        "id": "a55baaaf-97bc-4ac7-abf9-48d4a93db371"
      },
      "outputs": [],
      "source": [
        "def subtract_background(video_path, background, threshold=30, scene_threshold=0.05, pixel_thresh=25, dynamic_bg=False):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    ret, prev_frame = cap.read()\n",
        "    if not ret:\n",
        "        return\n",
        "    prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
        "    frame_index = 1\n",
        "    background = background.astype(\"float32\")\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
        "    alpha = 0.01\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frame_resized = cv2.resize(frame, (512, 512))\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        diff_scene = cv2.absdiff(gray, prev_gray)\n",
        "        scene_change_ratio = np.sum(diff_scene > pixel_thresh) / diff_scene.size\n",
        "        if scene_change_ratio > scene_threshold:\n",
        "            print(f\"[Scene Change] Frame: {frame_index} | Change: {scene_change_ratio * 100:.2f}%\")\n",
        "            prev_gray = gray.copy()\n",
        "            cv2.imshow('Original', frame_resized)\n",
        "            cv2.imshow('Foreground Mask', diff_scene)\n",
        "            if cv2.waitKey(30) & 0xFF == 27:\n",
        "                break\n",
        "            frame_index += 1\n",
        "            continue\n",
        "        diff = cv2.absdiff(gray, background.astype(\"uint8\"))\n",
        "        _, fg_mask = cv2.threshold(diff, threshold, 255, cv2.THRESH_BINARY)\n",
        "        fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_OPEN, kernel)\n",
        "        fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_DILATE, kernel)\n",
        "        fg_mask = cv2.resize(fg_mask, (512, 512))\n",
        "        cv2.imshow('Original', frame_resized)\n",
        "        cv2.imshow('Foreground Mask', fg_mask)\n",
        "        if dynamic_bg:\n",
        "            background = cv2.addWeighted(gray.astype(\"float32\"), alpha, background, 1 - alpha, 0)\n",
        "        if cv2.waitKey(30) & 0xFF == 27:\n",
        "            break\n",
        "        prev_gray = gray.copy()\n",
        "        frame_index += 1\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c6c493a-3a31-4d8d-9466-904b523c6562",
      "metadata": {
        "id": "7c6c493a-3a31-4d8d-9466-904b523c6562",
        "outputId": "96f4af4b-3e1a-4e34-ffbd-3909e42b9446"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Estimating Scene Threshold...\n",
            "[Scene Change] Frame: 13 | Change: 55.58%\n",
            "[Scene Change] Frame: 80 | Change: 53.76%\n",
            "[Scene Change] Frame: 150 | Change: 52.78%\n",
            "[Scene Change] Frame: 206 | Change: 47.06%\n",
            "[Scene Change] Frame: 269 | Change: 51.29%\n",
            "[Scene Change] Frame: 339 | Change: 52.43%\n",
            "[Scene Change] Frame: 396 | Change: 56.66%\n",
            "[Scene Change] Frame: 482 | Change: 48.20%\n",
            "[Scene Change] Frame: 540 | Change: 47.01%\n"
          ]
        }
      ],
      "source": [
        "path = 'steyn.mp4'\n",
        "bg = compute_background(path)\n",
        "print(\"Estimating Scene Threshold...\")\n",
        "scene_thresh = estimate_scene_threshold(path)\n",
        "subtract_background(path, bg, scene_threshold=scene_thresh, dynamic_bg=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6cc1ce6-de8d-49e9-9805-8129fbd907a4",
      "metadata": {
        "id": "a6cc1ce6-de8d-49e9-9805-8129fbd907a4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}